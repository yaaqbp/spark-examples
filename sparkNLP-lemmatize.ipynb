{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d630fe2-4091-4ebc-b153-b10e8ad3d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.functions import monotonically_increasing_id, col, collect_list, concat_ws, udf, expr, split\n",
    "from pyspark.sql.types import IntegerType, ArrayType, StringType, DoubleType, MapType\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Window\n",
    "\n",
    "from pyspark.ml.feature import Tokenizer as MLTokenizer\n",
    "from pyspark.ml.feature import HashingTF, IDF, CountVectorizer, StopWordsRemover\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1282f17d-470c-4295-a379-04bf874ab03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jpietraszek/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jpietraszek/.ivy2/jars\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-8caaba90-4029-459a-8c77-c282e561b048;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;5.1.4 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound com.google.cloud#google-cloud-storage;2.20.1 in central\n",
      "\tfound com.google.guava#guava;31.1-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0.1 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.3 in central\n",
      "\tfound com.google.http-client#google-http-client;1.43.0 in central\n",
      "\tfound io.opencensus#opencensus-contrib-http-util;0.31.1 in central\n",
      "\tfound com.google.http-client#google-http-client-jackson2;1.43.0 in central\n",
      "\tfound com.google.http-client#google-http-client-gson;1.43.0 in central\n",
      "\tfound com.google.api-client#google-api-client;2.2.0 in central\n",
      "\tfound commons-codec#commons-codec;1.15 in central\n",
      "\tfound com.google.oauth-client#google-oauth-client;1.34.1 in central\n",
      "\tfound com.google.http-client#google-http-client-apache-v2;1.43.0 in central\n",
      "\tfound com.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 in central\n",
      "\tfound com.google.code.gson#gson;2.10.1 in central\n",
      "\tfound com.google.cloud#google-cloud-core;2.12.0 in central\n",
      "\tfound io.grpc#grpc-context;1.53.0 in central\n",
      "\tfound com.google.auto.value#auto-value-annotations;1.10.1 in central\n",
      "\tfound com.google.auto.value#auto-value;1.10.1 in central\n",
      "\tfound javax.annotation#javax.annotation-api;1.3.2 in central\n",
      "\tfound commons-logging#commons-logging;1.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-http;2.12.0 in central\n",
      "\tfound com.google.http-client#google-http-client-appengine;1.43.0 in central\n",
      "\tfound com.google.api#gax-httpjson;0.108.2 in central\n",
      "\tfound com.google.cloud#google-cloud-core-grpc;2.12.0 in central\n",
      "\tfound io.grpc#grpc-alts;1.53.0 in central\n",
      "\tfound io.grpc#grpc-grpclb;1.53.0 in central\n",
      "\tfound org.conscrypt#conscrypt-openjdk-uber;2.5.2 in central\n",
      "\tfound io.grpc#grpc-auth;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf;1.53.0 in central\n",
      "\tfound io.grpc#grpc-protobuf-lite;1.53.0 in central\n",
      "\tfound io.grpc#grpc-core;1.53.0 in central\n",
      "\tfound com.google.api#gax;2.23.2 in central\n",
      "\tfound com.google.api#gax-grpc;2.23.2 in central\n",
      "\tfound com.google.auth#google-auth-library-credentials;1.16.0 in central\n",
      "\tfound com.google.auth#google-auth-library-oauth2-http;1.16.0 in central\n",
      "\tfound com.google.api#api-common;2.6.2 in central\n",
      "\tfound io.opencensus#opencensus-api;0.31.1 in central\n",
      "\tfound com.google.api.grpc#proto-google-iam-v1;1.9.2 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.21.12 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.21.12 in central\n",
      "\tfound com.google.api.grpc#proto-google-common-protos;2.14.2 in central\n",
      "\tfound org.threeten#threetenbp;1.6.5 in central\n",
      "\tfound com.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.14.2 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound io.grpc#grpc-api;1.53.0 in central\n",
      "\tfound io.grpc#grpc-stub;1.53.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.31.0 in central\n",
      "\tfound io.perfmark#perfmark-api;0.26.0 in central\n",
      "\tfound com.google.android#annotations;4.1.1.4 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.22 in central\n",
      "\tfound io.opencensus#opencensus-proto;0.2.0 in central\n",
      "\tfound io.grpc#grpc-services;1.53.0 in central\n",
      "\tfound com.google.re2j#re2j;1.6 in central\n",
      "\tfound io.grpc#grpc-netty-shaded;1.53.0 in central\n",
      "\tfound io.grpc#grpc-googleapis;1.53.0 in central\n",
      "\tfound io.grpc#grpc-xds;1.53.0 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 in central\n",
      "\tfound com.microsoft.onnxruntime#onnxruntime;1.15.0 in central\n",
      ":: resolution report :: resolve 756ms :: artifacts dl 23ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.14.2 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.android#annotations;4.1.1.4 from central in [default]\n",
      "\tcom.google.api#api-common;2.6.2 from central in [default]\n",
      "\tcom.google.api#gax;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-grpc;2.23.2 from central in [default]\n",
      "\tcom.google.api#gax-httpjson;0.108.2 from central in [default]\n",
      "\tcom.google.api-client#google-api-client;2.2.0 from central in [default]\n",
      "\tcom.google.api.grpc#gapic-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#grpc-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-cloud-storage-v2;2.20.1-alpha from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-common-protos;2.14.2 from central in [default]\n",
      "\tcom.google.api.grpc#proto-google-iam-v1;1.9.2 from central in [default]\n",
      "\tcom.google.apis#google-api-services-storage;v1-rev20220705-2.0.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-credentials;1.16.0 from central in [default]\n",
      "\tcom.google.auth#google-auth-library-oauth2-http;1.16.0 from central in [default]\n",
      "\tcom.google.auto.value#auto-value;1.10.1 from central in [default]\n",
      "\tcom.google.auto.value#auto-value-annotations;1.10.1 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-grpc;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-core-http;2.12.0 from central in [default]\n",
      "\tcom.google.cloud#google-cloud-storage;2.20.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.10.1 from central in [default]\n",
      "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0.1 from central in [default]\n",
      "\tcom.google.guava#guava;31.1-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.http-client#google-http-client;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-apache-v2;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-appengine;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-gson;1.43.0 from central in [default]\n",
      "\tcom.google.http-client#google-http-client-jackson2;1.43.0 from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.3 from central in [default]\n",
      "\tcom.google.oauth-client#google-oauth-client;1.34.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.21.12 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.21.12 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.6 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;5.1.4 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.4 from central in [default]\n",
      "\tcom.microsoft.onnxruntime#onnxruntime;1.15.0 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.15 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tio.grpc#grpc-alts;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-api;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-auth;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-context;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-core;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-googleapis;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-grpclb;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-netty-shaded;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-protobuf-lite;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-services;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-stub;1.53.0 from central in [default]\n",
      "\tio.grpc#grpc-xds;1.53.0 from central in [default]\n",
      "\tio.opencensus#opencensus-api;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-contrib-http-util;0.31.1 from central in [default]\n",
      "\tio.opencensus#opencensus-proto;0.2.0 from central in [default]\n",
      "\tio.perfmark#perfmark-api;0.26.0 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tjavax.annotation#javax.annotation-api;1.3.2 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.31.0 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.22 from central in [default]\n",
      "\torg.conscrypt#conscrypt-openjdk-uber;2.5.2 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.threeten#threetenbp;1.6.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 by [com.google.protobuf#protobuf-java-util;3.21.12] in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 by [com.google.protobuf#protobuf-java;3.21.12] in [default]\n",
      "\tcom.google.code.gson#gson;2.3 by [com.google.code.gson#gson;2.10.1] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   75  |   0   |   0   |   3   ||   72  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-8caaba90-4029-459a-8c77-c282e561b048\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 72 already retrieved (0kB/12ms)\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/19 12:06:29 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkNLP-TFIDF\")\\\n",
    "    .config(\"spark.executor.instances\", \"2\") \\\n",
    "    .config(\"spark.executor.memory\", \"30G\") \\\n",
    "    .config(\"spark.executor.cores\", \"24\") \\\n",
    "    .config(\"spark.executor.cores.max\", \"24\") \\\n",
    "    .config(\"spark.driver.memory\", \"20G\") \\\n",
    "  \n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.1.4\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44247407-587f-4aef-8b08-cc5ed63679a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 ms, sys: 2.36 ms, total: 14.4 ms\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = spark.read.json('/user/jpietraszek/arxiv-metadata-oai-snapshot.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eeb3644-1967-48ab-9aa2-825ba329ac35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.43 ms, sys: 2.44 ms, total: 6.87 ms\n",
      "Wall time: 117 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = df.filter(~col(\"categories\").like(\"% %\"))\n",
    "df = df.withColumn(\"abstract\", f.lower(col(\"abstract\")))\n",
    "df = df.withColumn(\"abstract\", f.regexp_replace(col(\"abstract\"), \"[^a-zA-Z\\\\s]\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d707a1-20ac-45e8-b6f0-9065f21aea6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.sample(fraction = .001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0170126f-6fb1-43df-830a-a3939fbe09c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemma_spacylookup download started this may take some time.\n",
      "Approximate size to download 417 KB\n",
      "[OK!]\n",
      "CPU times: user 27 ms, sys: 11.4 ms, total: 38.4 ms\n",
      "Wall time: 4.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documentAssembler = DocumentAssembler() \\\n",
    ".setInputCol(\"abstract\") \\\n",
    ".setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector() \\\n",
    ".setInputCols([\"document\"]) \\\n",
    ".setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    ".setInputCols([\"sentence\"]) \\\n",
    ".setOutputCol(\"token\")\n",
    "\n",
    "stemmer = Stemmer() \\\n",
    ".setInputCols([\"token\"]). \\\n",
    "setOutputCol(\"stem\")\n",
    "\n",
    "lemmatizer = LemmatizerModel.pretrained(\"lemma_spacylookup\",\"en\") \\\n",
    ".setInputCols([\"stem\"]) \\\n",
    ".setOutputCol(\"lemma\")\n",
    "\n",
    "stopwords_cleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"lemma\"]) \\\n",
    "    .setOutputCol(\"clean_lemma\") \\\n",
    "    .setCaseSensitive(False)\n",
    "\n",
    "pipeline = Pipeline() \\\n",
    ".setStages([\n",
    "documentAssembler,\n",
    "sentenceDetector,\n",
    "tokenizer,\n",
    "stemmer,\n",
    "lemmatizer,\n",
    "stopwords_cleaner\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fc34b9b-f5b3-47ba-b873-6102cb8494db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.7 ms, sys: 8.13 ms, total: 49.9 ms\n",
      "Wall time: 335 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78995f36-a992-4e03-a9f6-81cc470f35d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(abstract='  a fully differential calculation in perturbative quantum chromodynamics is\\npresented for the production of massive photon pairs at hadron colliders all\\nnexttoleading order perturbative contributions from quarkantiquark\\ngluonantiquark and gluongluon subprocesses are included as well as\\nallorders resummation of initialstate gluon radiation valid at\\nnexttonexttoleading logarithmic accuracy the region of phase space is\\nspecified in which the calculation is most reliable good agreement is\\ndemonstrated with data from the fermilab tevatron and predictions are made for\\nmore detailed tests with cdf and do data predictions are shown for\\ndistributions of diphoton pairs produced at the energy of the large hadron\\ncollider lhc distributions of the diphoton pairs from the decay of a higgs\\nboson are contrasted with those produced from qcd processes at the lhc showing\\nthat enhanced sensitivity to the signal can be obtained with judicious\\nselection of events\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('abstract').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31bec64b-97a2-4fc3-9583-1687d1f43679",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(result=['fulli', 'differenti', 'calcul', 'perturb', 'quantum', 'chromodynam', 'present', 'product', 'massiv', 'photon', 'pair', 'hadron', 'collid', 'nexttolead', 'order', 'perturb', 'contribut', 'quarkantiquark', 'gluonantiquark', 'gluongluon', 'subprocess', 'ar', 'includ', 'good', 'allord', 'resumm', 'initialst', 'gluon', 'radiat', 'valid', 'nexttonexttolead', 'logarithm', 'accuraci', 'region', 'phase', 'space', 'specifi', 'calcul', 'much', 'reliabl', 'good', 'agreem', 'demonstr', 'datum', 'fermilab', 'tevatron', 'predict', 'ar', 'make', 'much', 'detail', 'test', 'cdf', 'datum', 'predict', 'ar', 'show', 'distribut', 'diphoton', 'pair', 'produc', 'energi', 'larg', 'hadron', 'collid', 'lhc', 'distribut', 'diphoton', 'pair', 'decai', 'higg', 'boson', 'ar', 'contrast', 'produc', 'qcd', 'process', 'lhc', 'showe', 'enhanc', 'sensit', 'signal', 'obtain', 'judici', 'select', 'event'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.selectExpr(\"clean_lemma.result\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5081da8-27bb-42ad-a1ed-be2b403aafed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================================================> (47 + 1) / 48]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 97.6 ms, sys: 27.6 ms, total: 125 ms\n",
      "Wall time: 2min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lemma_df = result.selectExpr(\"id\",\"clean_lemma.result\",\"categories\")\n",
    "lemma_df.write.format('parquet').mode(\"overwrite\").save(\"/user/jpietraszek/arxiv-lemmatized_preprocessed_spacy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae687563-ffd4-4c4d-9421-5db58925c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.7 ms, sys: 1.59 ms, total: 3.29 ms\n",
      "Wall time: 211 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/18 12:48:54 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: Master removed our application: KILLED\n",
      "23/11/18 12:48:54 ERROR Inbox: Ignoring error\n",
      "org.apache.spark.SparkException: Exiting due to error from cluster scheduler: Master removed our application: KILLED\n",
      "\tat org.apache.spark.errors.SparkCoreErrors$.clusterSchedulerError(SparkCoreErrors.scala:291)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.error(TaskSchedulerImpl.scala:981)\n",
      "\tat org.apache.spark.scheduler.cluster.StandaloneSchedulerBackend.dead(StandaloneSchedulerBackend.scala:165)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint.markDead(StandaloneAppClient.scala:263)\n",
      "\tat org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$receive$1.applyOrElse(StandaloneAppClient.scala:170)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tmp = spark.read.parquet('/user/jpietraszek/arxiv-lemmatized_preprocessed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce63b6-c3f8-4fcf-97b4-c0d3d225ae2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a6311d-8120-4131-81af-9addaeaed487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae71b8c1-fc84-4d0b-9d70-02b2afc34e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38113380-c646-4a51-b327-b906e0875332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65a11a4f-ad3d-458e-8a4c-25e994240712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 ms, sys: 1.77 ms, total: 3.49 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tmp = spark.read.parquet('/user/jpietraszek/arxiv-lemmatized_preprocessed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca20a876-310f-46b4-9662-0f547a6acb67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merged_df = merged_df.groupBy(\"categories\").agg(concat_ws(\" \", collect_list(\"result\")).alias(\"merged_result\"))\n",
    "\n",
    "merged_df = merged_df.withColumn(\"text_length\", length_udf(col(\"merged_result\")))\n",
    "merged_df = merged_df.orderBy(col(\"text_length\").desc())\n",
    "\n",
    "longest_text_row = merged_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "983ad3cc-7151-4a73-8a44-e327f60b3705",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:================================================>       (26 + 4) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----------+\n",
      "|       categories|       merged_result|text_length|\n",
      "+-----------------+--------------------+-----------+\n",
      "|         astro-ph|Massive Black Hol...|      85308|\n",
      "|         quant-ph|The strong light-...|      59939|\n",
      "|           hep-ph|In QCD with $N_c$...|      54516|\n",
      "|            cs.CV|Open-set logo rec...|      42189|\n",
      "|      astro-ph.GA|The L204 dark clo...|      36410|\n",
      "|           hep-th|The renormalized ...|      36009|\n",
      "|      astro-ph.SR|Hot subdwarf B st...|      35491|\n",
      "|cond-mat.mtrl-sci|The existence of ...|      35320|\n",
      "|      astro-ph.HE|We present a stat...|      31747|\n",
      "|            gr-qc|The crucial role ...|      29877|\n",
      "|cond-mat.mes-hall|The quasiparticle...|      28732|\n",
      "|          math.AP|We consider a con...|      24154|\n",
      "|    cs.IT math.IT|We examine the pr...|      23945|\n",
      "|          math.CO|What be the unavo...|      23486|\n",
      "|    cs.LG stat.ML|Differential priv...|      22338|\n",
      "|            cs.CL|This paper descri...|      21937|\n",
      "|            cs.LG|Meta-learning , d...|      18350|\n",
      "|      astro-ph.EP|One of the first ...|      17664|\n",
      "|  cond-mat.str-el|We investigate th...|      17435|\n",
      "|      astro-ph.CO|Weak lense source...|      16569|\n",
      "+-----------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5077d21b-c5a4-496e-bb59-8a6d46b1250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.withColumn(\"TextArray\", split(\"merged_result\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb5d81f0-e8ab-4c19-9721-107169fa5169",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=============================>                         (16 + 14) / 30]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----------+--------------------+\n",
      "|       categories|       merged_result|text_length|           TextArray|\n",
      "+-----------------+--------------------+-----------+--------------------+\n",
      "|         astro-ph|Massive Black Hol...|      85308|[Massive, Black, ...|\n",
      "|         quant-ph|The strong light-...|      59939|[The, strong, lig...|\n",
      "|           hep-ph|In QCD with $N_c$...|      54516|[In, QCD, with, $...|\n",
      "|            cs.CV|Open-set logo rec...|      42189|[Open-set, logo, ...|\n",
      "|      astro-ph.GA|The L204 dark clo...|      36410|[The, L204, dark,...|\n",
      "|           hep-th|The renormalized ...|      36009|[The, renormalize...|\n",
      "|      astro-ph.SR|Hot subdwarf B st...|      35491|[Hot, subdwarf, B...|\n",
      "|cond-mat.mtrl-sci|The existence of ...|      35320|[The, existence, ...|\n",
      "|      astro-ph.HE|We present a stat...|      31747|[We, present, a, ...|\n",
      "|            gr-qc|The crucial role ...|      29877|[The, crucial, ro...|\n",
      "|cond-mat.mes-hall|The quasiparticle...|      28732|[The, quasipartic...|\n",
      "|          math.AP|We consider a con...|      24154|[We, consider, a,...|\n",
      "|    cs.IT math.IT|We examine the pr...|      23945|[We, examine, the...|\n",
      "|          math.CO|What be the unavo...|      23486|[What, be, the, u...|\n",
      "|    cs.LG stat.ML|Differential priv...|      22338|[Differential, pr...|\n",
      "|            cs.CL|This paper descri...|      21937|[This, paper, des...|\n",
      "|            cs.LG|Meta-learning , d...|      18350|[Meta-learning, ,...|\n",
      "|      astro-ph.EP|One of the first ...|      17664|[One, of, the, fi...|\n",
      "|  cond-mat.str-el|We investigate th...|      17435|[We, investigate,...|\n",
      "|      astro-ph.CO|Weak lense source...|      16569|[Weak, lense, sou...|\n",
      "+-----------------+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merged_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "917a7715-f4f2-4a30-b9af-16ef3e0eba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import DocumentAssembler, Pipeline, LightPipeline\n",
    "from sparknlp.annotator import (\n",
    "    SentenceDetector,\n",
    "    Tokenizer,\n",
    "    YakeKeywordExtraction\n",
    ")\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Step 1: Transforms raw texts to `document` annotation\n",
    "document = DocumentAssembler() \\\n",
    "            .setInputCol(\"text\") \\\n",
    "            .setOutputCol(\"document\")\n",
    "\n",
    "# Step 2: Sentence Detection\n",
    "sentenceDetector = SentenceDetector() \\\n",
    "            .setInputCols(\"document\") \\\n",
    "            .setOutputCol(\"sentence\")\n",
    "\n",
    "# Step 3: Tokenization\n",
    "token = Tokenizer() \\\n",
    "            .setInputCols(\"sentence\") \\\n",
    "            .setOutputCol(\"token\") \\\n",
    "            .setContextChars([\"(\", \")\", \"?\", \"!\", \".\", \",\"])\n",
    "\n",
    "# Step 4: Keyword Extraction\n",
    "keywords = YakeKeywordExtraction() \\\n",
    "            .setInputCols(\"token\") \\\n",
    "            .setOutputCol(\"keywords\") \\\n",
    "            \n",
    "# Define the pipeline\n",
    "yake_pipeline = Pipeline(stages=[document, sentenceDetector, token, keywords])\n",
    "\n",
    "# Create an empty dataframe\n",
    "empty_df = spark.createDataFrame([['']]).toDF(\"text\")\n",
    "\n",
    "# Fit the dataframe to get the \n",
    "yake_Model = yake_pipeline.fit(empty_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "83c200c7-1997-4032-b6b6-f4a4106015d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_model = LightPipeline(yake_Model)\n",
    "\n",
    "text = '''\n",
    "google is acquiring data science community kaggle. Sources tell us that google is acquiring kaggle, a platform that hosts data science and machine learning competitions. Details about the transaction remain somewhat vague , but given that google is hosting its Cloud Next conference in san francisco this week, the official announcement could come as early as tomorrow. Reached by phone, kaggle co-founder ceo anthony goldbloom declined to deny that the acquisition is happening. google itself declined 'to comment on rumors'. kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom and Ben Hamner in 2010. The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche. The service is basically the de facto home for running data science and machine learning competitions. With kaggle, google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects). kaggle has a bit of a history with google, too, but that's pretty recent. Earlier this month, google and kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. That competition had some deep integrations with the google Cloud platform, too. Our understanding is that google will keep the service running - likely under its current name. While the acquisition is probably more about Kaggle's community than technology, kaggle did build some interesting tools for hosting its competition and 'kernels', too. On kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them 'scripts'). Like similar competition-centric sites, kaggle also runs a job board, too. It's unclear what google will do with that part of the service. According to Crunchbase, kaggle raised $12.5 million (though PitchBook says it's $12.75) since its launch in 2010. Investors in kaggle include Index Ventures, SV Angel, Max Levchin, Naval Ravikant, google chief economist Hal Varian, Khosla Ventures and Yuri Milner\n",
    "'''\n",
    "\n",
    "light_result = light_model.fullAnnotate(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9af09b51-709a-40eb-8b58-7c0d27097c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': [Annotation(document, 0, 2318, \n",
       "  google is acquiring data science community kaggle. Sources tell us that google is acquiring kaggle, a platform that hosts data science and machine learning competitions. Details about the transaction remain somewhat vague , but given that google is hosting its Cloud Next conference in san francisco this week, the official announcement could come as early as tomorrow. Reached by phone, kaggle co-founder ceo anthony goldbloom declined to deny that the acquisition is happening. google itself declined 'to comment on rumors'. kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom and Ben Hamner in 2010. The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche. The service is basically the de facto home for running data science and machine learning competitions. With kaggle, google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects). kaggle has a bit of a history with google, too, but that's pretty recent. Earlier this month, google and kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos. That competition had some deep integrations with the google Cloud platform, too. Our understanding is that google will keep the service running - likely under its current name. While the acquisition is probably more about Kaggle's community than technology, kaggle did build some interesting tools for hosting its competition and 'kernels', too. On kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them 'scripts'). Like similar competition-centric sites, kaggle also runs a job board, too. It's unclear what google will do with that part of the service. According to Crunchbase, kaggle raised $12.5 million (though PitchBook says it's $12.75) since its launch in 2010. Investors in kaggle include Index Ventures, SV Angel, Max Levchin, Naval Ravikant, google chief economist Hal Varian, Khosla Ventures and Yuri Milner\n",
       "  , {}, [])],\n",
       " 'sentence': [Annotation(document, 1, 50, google is acquiring data science community kaggle., {'sentence': '0'}, []),\n",
       "  Annotation(document, 52, 169, Sources tell us that google is acquiring kaggle, a platform that hosts data science and machine learning competitions., {'sentence': '1'}, []),\n",
       "  Annotation(document, 171, 369, Details about the transaction remain somewhat vague , but given that google is hosting its Cloud Next conference in san francisco this week, the official announcement could come as early as tomorrow., {'sentence': '2'}, []),\n",
       "  Annotation(document, 371, 479, Reached by phone, kaggle co-founder ceo anthony goldbloom declined to deny that the acquisition is happening., {'sentence': '3'}, []),\n",
       "  Annotation(document, 481, 647, google itself declined 'to comment on rumors'. kaggle, which has about half a million data scientists on its platform, was founded by Goldbloom and Ben Hamner in 2010., {'sentence': '4'}, []),\n",
       "  Annotation(document, 649, 838, The service got an early start and even though it has a few competitors like DrivenData, TopCoder and HackerRank, it has managed to stay well ahead of them by focusing on its specific niche., {'sentence': '5'}, []),\n",
       "  Annotation(document, 840, 941, The service is basically the de facto home for running data science and machine learning competitions., {'sentence': '6'}, []),\n",
       "  Annotation(document, 943, 1190, With kaggle, google is buying one of the largest and most active communities for data scientists - and with that, it will get increased mindshare in this community, too (though it already has plenty of that thanks to Tensorflow and other projects)., {'sentence': '7'}, []),\n",
       "  Annotation(document, 1192, 1264, kaggle has a bit of a history with google, too, but that's pretty recent., {'sentence': '8'}, []),\n",
       "  Annotation(document, 1266, 1395, Earlier this month, google and kaggle teamed up to host a $100,000 machine learning competition around classifying YouTube videos., {'sentence': '9'}, []),\n",
       "  Annotation(document, 1397, 1476, That competition had some deep integrations with the google Cloud platform, too., {'sentence': '10'}, []),\n",
       "  Annotation(document, 1478, 1572, Our understanding is that google will keep the service running - likely under its current name., {'sentence': '11'}, []),\n",
       "  Annotation(document, 1574, 1741, While the acquisition is probably more about Kaggle's community than technology, kaggle did build some interesting tools for hosting its competition and 'kernels', too., {'sentence': '12'}, []),\n",
       "  Annotation(document, 1743, 1913, On kaggle, kernels are basically the source code for analyzing data sets and developers can share this code on the platform (the company previously called them 'scripts')., {'sentence': '13'}, []),\n",
       "  Annotation(document, 1915, 1988, Like similar competition-centric sites, kaggle also runs a job board, too., {'sentence': '14'}, []),\n",
       "  Annotation(document, 1990, 2052, It's unclear what google will do with that part of the service., {'sentence': '15'}, []),\n",
       "  Annotation(document, 2054, 2167, According to Crunchbase, kaggle raised $12.5 million (though PitchBook says it's $12.75) since its launch in 2010., {'sentence': '16'}, []),\n",
       "  Annotation(document, 2169, 2317, Investors in kaggle include Index Ventures, SV Angel, Max Levchin, Naval Ravikant, google chief economist Hal Varian, Khosla Ventures and Yuri Milner, {'sentence': '17'}, [])],\n",
       " 'token': [Annotation(token, 1, 6, google, {'sentence': '0'}, []),\n",
       "  Annotation(token, 8, 9, is, {'sentence': '0'}, []),\n",
       "  Annotation(token, 11, 19, acquiring, {'sentence': '0'}, []),\n",
       "  Annotation(token, 21, 24, data, {'sentence': '0'}, []),\n",
       "  Annotation(token, 26, 32, science, {'sentence': '0'}, []),\n",
       "  Annotation(token, 34, 42, community, {'sentence': '0'}, []),\n",
       "  Annotation(token, 44, 49, kaggle, {'sentence': '0'}, []),\n",
       "  Annotation(token, 50, 50, ., {'sentence': '0'}, []),\n",
       "  Annotation(token, 52, 58, Sources, {'sentence': '1'}, []),\n",
       "  Annotation(token, 60, 63, tell, {'sentence': '1'}, []),\n",
       "  Annotation(token, 65, 66, us, {'sentence': '1'}, []),\n",
       "  Annotation(token, 68, 71, that, {'sentence': '1'}, []),\n",
       "  Annotation(token, 73, 78, google, {'sentence': '1'}, []),\n",
       "  Annotation(token, 80, 81, is, {'sentence': '1'}, []),\n",
       "  Annotation(token, 83, 91, acquiring, {'sentence': '1'}, []),\n",
       "  Annotation(token, 93, 98, kaggle, {'sentence': '1'}, []),\n",
       "  Annotation(token, 99, 99, ,, {'sentence': '1'}, []),\n",
       "  Annotation(token, 101, 101, a, {'sentence': '1'}, []),\n",
       "  Annotation(token, 103, 110, platform, {'sentence': '1'}, []),\n",
       "  Annotation(token, 112, 115, that, {'sentence': '1'}, []),\n",
       "  Annotation(token, 117, 121, hosts, {'sentence': '1'}, []),\n",
       "  Annotation(token, 123, 126, data, {'sentence': '1'}, []),\n",
       "  Annotation(token, 128, 134, science, {'sentence': '1'}, []),\n",
       "  Annotation(token, 136, 138, and, {'sentence': '1'}, []),\n",
       "  Annotation(token, 140, 146, machine, {'sentence': '1'}, []),\n",
       "  Annotation(token, 148, 155, learning, {'sentence': '1'}, []),\n",
       "  Annotation(token, 157, 168, competitions, {'sentence': '1'}, []),\n",
       "  Annotation(token, 169, 169, ., {'sentence': '1'}, []),\n",
       "  Annotation(token, 171, 177, Details, {'sentence': '2'}, []),\n",
       "  Annotation(token, 179, 183, about, {'sentence': '2'}, []),\n",
       "  Annotation(token, 185, 187, the, {'sentence': '2'}, []),\n",
       "  Annotation(token, 189, 199, transaction, {'sentence': '2'}, []),\n",
       "  Annotation(token, 201, 206, remain, {'sentence': '2'}, []),\n",
       "  Annotation(token, 208, 215, somewhat, {'sentence': '2'}, []),\n",
       "  Annotation(token, 217, 221, vague, {'sentence': '2'}, []),\n",
       "  Annotation(token, 223, 223, ,, {'sentence': '2'}, []),\n",
       "  Annotation(token, 225, 227, but, {'sentence': '2'}, []),\n",
       "  Annotation(token, 229, 233, given, {'sentence': '2'}, []),\n",
       "  Annotation(token, 235, 238, that, {'sentence': '2'}, []),\n",
       "  Annotation(token, 240, 245, google, {'sentence': '2'}, []),\n",
       "  Annotation(token, 247, 248, is, {'sentence': '2'}, []),\n",
       "  Annotation(token, 250, 256, hosting, {'sentence': '2'}, []),\n",
       "  Annotation(token, 258, 260, its, {'sentence': '2'}, []),\n",
       "  Annotation(token, 262, 266, Cloud, {'sentence': '2'}, []),\n",
       "  Annotation(token, 268, 271, Next, {'sentence': '2'}, []),\n",
       "  Annotation(token, 273, 282, conference, {'sentence': '2'}, []),\n",
       "  Annotation(token, 284, 285, in, {'sentence': '2'}, []),\n",
       "  Annotation(token, 287, 289, san, {'sentence': '2'}, []),\n",
       "  Annotation(token, 291, 299, francisco, {'sentence': '2'}, []),\n",
       "  Annotation(token, 301, 304, this, {'sentence': '2'}, []),\n",
       "  Annotation(token, 306, 309, week, {'sentence': '2'}, []),\n",
       "  Annotation(token, 310, 310, ,, {'sentence': '2'}, []),\n",
       "  Annotation(token, 312, 314, the, {'sentence': '2'}, []),\n",
       "  Annotation(token, 316, 323, official, {'sentence': '2'}, []),\n",
       "  Annotation(token, 325, 336, announcement, {'sentence': '2'}, []),\n",
       "  Annotation(token, 338, 342, could, {'sentence': '2'}, []),\n",
       "  Annotation(token, 344, 347, come, {'sentence': '2'}, []),\n",
       "  Annotation(token, 349, 350, as, {'sentence': '2'}, []),\n",
       "  Annotation(token, 352, 356, early, {'sentence': '2'}, []),\n",
       "  Annotation(token, 358, 359, as, {'sentence': '2'}, []),\n",
       "  Annotation(token, 361, 368, tomorrow, {'sentence': '2'}, []),\n",
       "  Annotation(token, 369, 369, ., {'sentence': '2'}, []),\n",
       "  Annotation(token, 371, 377, Reached, {'sentence': '3'}, []),\n",
       "  Annotation(token, 379, 380, by, {'sentence': '3'}, []),\n",
       "  Annotation(token, 382, 386, phone, {'sentence': '3'}, []),\n",
       "  Annotation(token, 387, 387, ,, {'sentence': '3'}, []),\n",
       "  Annotation(token, 389, 394, kaggle, {'sentence': '3'}, []),\n",
       "  Annotation(token, 396, 405, co-founder, {'sentence': '3'}, []),\n",
       "  Annotation(token, 407, 409, ceo, {'sentence': '3'}, []),\n",
       "  Annotation(token, 411, 417, anthony, {'sentence': '3'}, []),\n",
       "  Annotation(token, 419, 427, goldbloom, {'sentence': '3'}, []),\n",
       "  Annotation(token, 429, 436, declined, {'sentence': '3'}, []),\n",
       "  Annotation(token, 438, 439, to, {'sentence': '3'}, []),\n",
       "  Annotation(token, 441, 444, deny, {'sentence': '3'}, []),\n",
       "  Annotation(token, 446, 449, that, {'sentence': '3'}, []),\n",
       "  Annotation(token, 451, 453, the, {'sentence': '3'}, []),\n",
       "  Annotation(token, 455, 465, acquisition, {'sentence': '3'}, []),\n",
       "  Annotation(token, 467, 468, is, {'sentence': '3'}, []),\n",
       "  Annotation(token, 470, 478, happening, {'sentence': '3'}, []),\n",
       "  Annotation(token, 479, 479, ., {'sentence': '3'}, []),\n",
       "  Annotation(token, 481, 486, google, {'sentence': '4'}, []),\n",
       "  Annotation(token, 488, 493, itself, {'sentence': '4'}, []),\n",
       "  Annotation(token, 495, 502, declined, {'sentence': '4'}, []),\n",
       "  Annotation(token, 504, 506, 'to, {'sentence': '4'}, []),\n",
       "  Annotation(token, 508, 514, comment, {'sentence': '4'}, []),\n",
       "  Annotation(token, 516, 517, on, {'sentence': '4'}, []),\n",
       "  Annotation(token, 519, 525, rumors', {'sentence': '4'}, []),\n",
       "  Annotation(token, 526, 526, ., {'sentence': '4'}, []),\n",
       "  Annotation(token, 528, 533, kaggle, {'sentence': '4'}, []),\n",
       "  Annotation(token, 534, 534, ,, {'sentence': '4'}, []),\n",
       "  Annotation(token, 536, 540, which, {'sentence': '4'}, []),\n",
       "  Annotation(token, 542, 544, has, {'sentence': '4'}, []),\n",
       "  Annotation(token, 546, 550, about, {'sentence': '4'}, []),\n",
       "  Annotation(token, 552, 555, half, {'sentence': '4'}, []),\n",
       "  Annotation(token, 557, 557, a, {'sentence': '4'}, []),\n",
       "  Annotation(token, 559, 565, million, {'sentence': '4'}, []),\n",
       "  Annotation(token, 567, 570, data, {'sentence': '4'}, []),\n",
       "  Annotation(token, 572, 581, scientists, {'sentence': '4'}, []),\n",
       "  Annotation(token, 583, 584, on, {'sentence': '4'}, []),\n",
       "  Annotation(token, 586, 588, its, {'sentence': '4'}, []),\n",
       "  Annotation(token, 590, 597, platform, {'sentence': '4'}, []),\n",
       "  Annotation(token, 598, 598, ,, {'sentence': '4'}, []),\n",
       "  Annotation(token, 600, 602, was, {'sentence': '4'}, []),\n",
       "  Annotation(token, 604, 610, founded, {'sentence': '4'}, []),\n",
       "  Annotation(token, 612, 613, by, {'sentence': '4'}, []),\n",
       "  Annotation(token, 615, 623, Goldbloom, {'sentence': '4'}, []),\n",
       "  Annotation(token, 625, 627, and, {'sentence': '4'}, []),\n",
       "  Annotation(token, 629, 631, Ben, {'sentence': '4'}, []),\n",
       "  Annotation(token, 633, 638, Hamner, {'sentence': '4'}, []),\n",
       "  Annotation(token, 640, 641, in, {'sentence': '4'}, []),\n",
       "  Annotation(token, 643, 646, 2010, {'sentence': '4'}, []),\n",
       "  Annotation(token, 647, 647, ., {'sentence': '4'}, []),\n",
       "  Annotation(token, 649, 651, The, {'sentence': '5'}, []),\n",
       "  Annotation(token, 653, 659, service, {'sentence': '5'}, []),\n",
       "  Annotation(token, 661, 663, got, {'sentence': '5'}, []),\n",
       "  Annotation(token, 665, 666, an, {'sentence': '5'}, []),\n",
       "  Annotation(token, 668, 672, early, {'sentence': '5'}, []),\n",
       "  Annotation(token, 674, 678, start, {'sentence': '5'}, []),\n",
       "  Annotation(token, 680, 682, and, {'sentence': '5'}, []),\n",
       "  Annotation(token, 684, 687, even, {'sentence': '5'}, []),\n",
       "  Annotation(token, 689, 694, though, {'sentence': '5'}, []),\n",
       "  Annotation(token, 696, 697, it, {'sentence': '5'}, []),\n",
       "  Annotation(token, 699, 701, has, {'sentence': '5'}, []),\n",
       "  Annotation(token, 703, 703, a, {'sentence': '5'}, []),\n",
       "  Annotation(token, 705, 707, few, {'sentence': '5'}, []),\n",
       "  Annotation(token, 709, 719, competitors, {'sentence': '5'}, []),\n",
       "  Annotation(token, 721, 724, like, {'sentence': '5'}, []),\n",
       "  Annotation(token, 726, 735, DrivenData, {'sentence': '5'}, []),\n",
       "  Annotation(token, 736, 736, ,, {'sentence': '5'}, []),\n",
       "  Annotation(token, 738, 745, TopCoder, {'sentence': '5'}, []),\n",
       "  Annotation(token, 747, 749, and, {'sentence': '5'}, []),\n",
       "  Annotation(token, 751, 760, HackerRank, {'sentence': '5'}, []),\n",
       "  Annotation(token, 761, 761, ,, {'sentence': '5'}, []),\n",
       "  Annotation(token, 763, 764, it, {'sentence': '5'}, []),\n",
       "  Annotation(token, 766, 768, has, {'sentence': '5'}, []),\n",
       "  Annotation(token, 770, 776, managed, {'sentence': '5'}, []),\n",
       "  Annotation(token, 778, 779, to, {'sentence': '5'}, []),\n",
       "  Annotation(token, 781, 784, stay, {'sentence': '5'}, []),\n",
       "  Annotation(token, 786, 789, well, {'sentence': '5'}, []),\n",
       "  Annotation(token, 791, 795, ahead, {'sentence': '5'}, []),\n",
       "  Annotation(token, 797, 798, of, {'sentence': '5'}, []),\n",
       "  Annotation(token, 800, 803, them, {'sentence': '5'}, []),\n",
       "  Annotation(token, 805, 806, by, {'sentence': '5'}, []),\n",
       "  Annotation(token, 808, 815, focusing, {'sentence': '5'}, []),\n",
       "  Annotation(token, 817, 818, on, {'sentence': '5'}, []),\n",
       "  Annotation(token, 820, 822, its, {'sentence': '5'}, []),\n",
       "  Annotation(token, 824, 831, specific, {'sentence': '5'}, []),\n",
       "  Annotation(token, 833, 837, niche, {'sentence': '5'}, []),\n",
       "  Annotation(token, 838, 838, ., {'sentence': '5'}, []),\n",
       "  Annotation(token, 840, 842, The, {'sentence': '6'}, []),\n",
       "  Annotation(token, 844, 850, service, {'sentence': '6'}, []),\n",
       "  Annotation(token, 852, 853, is, {'sentence': '6'}, []),\n",
       "  Annotation(token, 855, 863, basically, {'sentence': '6'}, []),\n",
       "  Annotation(token, 865, 867, the, {'sentence': '6'}, []),\n",
       "  Annotation(token, 869, 870, de, {'sentence': '6'}, []),\n",
       "  Annotation(token, 872, 876, facto, {'sentence': '6'}, []),\n",
       "  Annotation(token, 878, 881, home, {'sentence': '6'}, []),\n",
       "  Annotation(token, 883, 885, for, {'sentence': '6'}, []),\n",
       "  Annotation(token, 887, 893, running, {'sentence': '6'}, []),\n",
       "  Annotation(token, 895, 898, data, {'sentence': '6'}, []),\n",
       "  Annotation(token, 900, 906, science, {'sentence': '6'}, []),\n",
       "  Annotation(token, 908, 910, and, {'sentence': '6'}, []),\n",
       "  Annotation(token, 912, 918, machine, {'sentence': '6'}, []),\n",
       "  Annotation(token, 920, 927, learning, {'sentence': '6'}, []),\n",
       "  Annotation(token, 929, 940, competitions, {'sentence': '6'}, []),\n",
       "  Annotation(token, 941, 941, ., {'sentence': '6'}, []),\n",
       "  Annotation(token, 943, 946, With, {'sentence': '7'}, []),\n",
       "  Annotation(token, 948, 953, kaggle, {'sentence': '7'}, []),\n",
       "  Annotation(token, 954, 954, ,, {'sentence': '7'}, []),\n",
       "  Annotation(token, 956, 961, google, {'sentence': '7'}, []),\n",
       "  Annotation(token, 963, 964, is, {'sentence': '7'}, []),\n",
       "  Annotation(token, 966, 971, buying, {'sentence': '7'}, []),\n",
       "  Annotation(token, 973, 975, one, {'sentence': '7'}, []),\n",
       "  Annotation(token, 977, 978, of, {'sentence': '7'}, []),\n",
       "  Annotation(token, 980, 982, the, {'sentence': '7'}, []),\n",
       "  Annotation(token, 984, 990, largest, {'sentence': '7'}, []),\n",
       "  Annotation(token, 992, 994, and, {'sentence': '7'}, []),\n",
       "  Annotation(token, 996, 999, most, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1001, 1006, active, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1008, 1018, communities, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1020, 1022, for, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1024, 1027, data, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1029, 1038, scientists, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1040, 1040, -, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1042, 1044, and, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1046, 1049, with, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1051, 1054, that, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1055, 1055, ,, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1057, 1058, it, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1060, 1063, will, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1065, 1067, get, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1069, 1077, increased, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1079, 1087, mindshare, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1089, 1090, in, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1092, 1095, this, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1097, 1105, community, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1106, 1106, ,, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1108, 1110, too, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1112, 1112, (, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1113, 1118, though, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1120, 1121, it, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1123, 1129, already, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1131, 1133, has, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1135, 1140, plenty, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1142, 1143, of, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1145, 1148, that, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1150, 1155, thanks, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1157, 1158, to, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1160, 1169, Tensorflow, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1171, 1173, and, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1175, 1179, other, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1181, 1188, projects, {'sentence': '7'}, []),\n",
       "  Annotation(token, 1189, 1190, )., {'sentence': '7'}, []),\n",
       "  Annotation(token, 1192, 1197, kaggle, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1199, 1201, has, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1203, 1203, a, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1205, 1207, bit, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1209, 1210, of, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1212, 1212, a, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1214, 1220, history, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1222, 1225, with, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1227, 1232, google, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1233, 1233, ,, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1235, 1237, too, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1238, 1238, ,, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1240, 1242, but, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1244, 1249, that's, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1251, 1256, pretty, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1258, 1263, recent, {'sentence': '8'}, []),\n",
       "  Annotation(token, 1264, 1264, ., {'sentence': '8'}, []),\n",
       "  Annotation(token, 1266, 1272, Earlier, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1274, 1277, this, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1279, 1283, month, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1284, 1284, ,, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1286, 1291, google, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1293, 1295, and, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1297, 1302, kaggle, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1304, 1309, teamed, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1311, 1312, up, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1314, 1315, to, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1317, 1320, host, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1322, 1322, a, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1324, 1331, $100,000, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1333, 1339, machine, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1341, 1348, learning, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1350, 1360, competition, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1362, 1367, around, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1369, 1379, classifying, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1381, 1387, YouTube, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1389, 1394, videos, {'sentence': '9'}, []),\n",
       "  Annotation(token, 1395, 1395, ., {'sentence': '9'}, []),\n",
       "  Annotation(token, 1397, 1400, That, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1402, 1412, competition, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1414, 1416, had, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1418, 1421, some, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1423, 1426, deep, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1428, 1439, integrations, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1441, 1444, with, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1446, 1448, the, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1450, 1455, google, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1457, 1461, Cloud, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1463, 1470, platform, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1471, 1471, ,, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1473, 1475, too, {'sentence': '10'}, []),\n",
       "  Annotation(token, 1476, 1476, ., {'sentence': '10'}, []),\n",
       "  Annotation(token, 1478, 1480, Our, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1482, 1494, understanding, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1496, 1497, is, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1499, 1502, that, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1504, 1509, google, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1511, 1514, will, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1516, 1519, keep, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1521, 1523, the, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1525, 1531, service, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1533, 1539, running, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1541, 1541, -, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1543, 1548, likely, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1550, 1554, under, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1556, 1558, its, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1560, 1566, current, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1568, 1571, name, {'sentence': '11'}, []),\n",
       "  Annotation(token, 1572, 1572, ., {'sentence': '11'}, []),\n",
       "  Annotation(token, 1574, 1578, While, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1580, 1582, the, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1584, 1594, acquisition, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1596, 1597, is, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1599, 1606, probably, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1608, 1611, more, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1613, 1617, about, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1619, 1626, Kaggle's, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1628, 1636, community, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1638, 1641, than, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1643, 1652, technology, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1653, 1653, ,, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1655, 1660, kaggle, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1662, 1664, did, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1666, 1670, build, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1672, 1675, some, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1677, 1687, interesting, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1689, 1693, tools, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1695, 1697, for, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1699, 1705, hosting, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1707, 1709, its, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1711, 1721, competition, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1723, 1725, and, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1727, 1735, 'kernels', {'sentence': '12'}, []),\n",
       "  Annotation(token, 1736, 1736, ,, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1738, 1740, too, {'sentence': '12'}, []),\n",
       "  Annotation(token, 1741, 1741, ., {'sentence': '12'}, []),\n",
       "  Annotation(token, 1743, 1744, On, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1746, 1751, kaggle, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1752, 1752, ,, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1754, 1760, kernels, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1762, 1764, are, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1766, 1774, basically, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1776, 1778, the, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1780, 1785, source, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1787, 1790, code, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1792, 1794, for, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1796, 1804, analyzing, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1806, 1809, data, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1811, 1814, sets, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1816, 1818, and, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1820, 1829, developers, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1831, 1833, can, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1835, 1839, share, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1841, 1844, this, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1846, 1849, code, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1851, 1852, on, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1854, 1856, the, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1858, 1865, platform, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1867, 1867, (, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1868, 1870, the, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1872, 1878, company, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1880, 1889, previously, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1891, 1896, called, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1898, 1901, them, {'sentence': '13'}, []),\n",
       "  Annotation(token, 1903, 1911, 'scripts', {'sentence': '13'}, []),\n",
       "  Annotation(token, 1912, 1913, )., {'sentence': '13'}, []),\n",
       "  Annotation(token, 1915, 1918, Like, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1920, 1926, similar, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1928, 1946, competition-centric, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1948, 1952, sites, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1953, 1953, ,, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1955, 1960, kaggle, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1962, 1965, also, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1967, 1970, runs, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1972, 1972, a, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1974, 1976, job, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1978, 1982, board, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1983, 1983, ,, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1985, 1987, too, {'sentence': '14'}, []),\n",
       "  Annotation(token, 1988, 1988, ., {'sentence': '14'}, []),\n",
       "  Annotation(token, 1990, 1993, It's, {'sentence': '15'}, []),\n",
       "  Annotation(token, 1995, 2001, unclear, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2003, 2006, what, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2008, 2013, google, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2015, 2018, will, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2020, 2021, do, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2023, 2026, with, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2028, 2031, that, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2033, 2036, part, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2038, 2039, of, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2041, 2043, the, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2045, 2051, service, {'sentence': '15'}, []),\n",
       "  Annotation(token, 2052, 2052, ., {'sentence': '15'}, []),\n",
       "  Annotation(token, 2054, 2062, According, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2064, 2065, to, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2067, 2076, Crunchbase, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2077, 2077, ,, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2079, 2084, kaggle, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2086, 2091, raised, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2093, 2097, $12.5, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2099, 2105, million, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2107, 2107, (, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2108, 2113, though, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2115, 2123, PitchBook, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2125, 2128, says, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2130, 2133, it's, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2135, 2140, $12.75, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2141, 2141, ), {'sentence': '16'}, []),\n",
       "  Annotation(token, 2143, 2147, since, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2149, 2151, its, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2153, 2158, launch, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2160, 2161, in, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2163, 2166, 2010, {'sentence': '16'}, []),\n",
       "  Annotation(token, 2167, 2167, ., {'sentence': '16'}, []),\n",
       "  Annotation(token, 2169, 2177, Investors, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2179, 2180, in, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2182, 2187, kaggle, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2189, 2195, include, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2197, 2201, Index, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2203, 2210, Ventures, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2211, 2211, ,, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2213, 2214, SV, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2216, 2220, Angel, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2221, 2221, ,, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2223, 2225, Max, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2227, 2233, Levchin, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2234, 2234, ,, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2236, 2240, Naval, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2242, 2249, Ravikant, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2250, 2250, ,, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2252, 2257, google, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2259, 2263, chief, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2265, 2273, economist, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2275, 2277, Hal, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2279, 2284, Varian, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2285, 2285, ,, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2287, 2292, Khosla, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2294, 2301, Ventures, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2303, 2305, and, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2307, 2310, Yuri, {'sentence': '17'}, []),\n",
       "  Annotation(token, 2312, 2317, Milner, {'sentence': '17'}, [])],\n",
       " 'keywords': [Annotation(chunk, 11, 24, acquiring data, {'score': '0.8442443542640019', 'sentence': '0'}, []),\n",
       "  Annotation(chunk, 21, 32, data science, {'score': '0.2558562206412746', 'sentence': '0'}, []),\n",
       "  Annotation(chunk, 26, 42, science community, {'score': '1.1528025958413988', 'sentence': '0'}, []),\n",
       "  Annotation(chunk, 34, 49, community kaggle, {'score': '1.0406282445036967', 'sentence': '0'}, []),\n",
       "  Annotation(chunk, 83, 98, acquiring kaggle, {'score': '0.8492390247747267', 'sentence': '1'}, []),\n",
       "  Annotation(chunk, 117, 126, hosts data, {'score': '1.2036912791760745', 'sentence': '1'}, []),\n",
       "  Annotation(chunk, 123, 134, data science, {'score': '0.2558562206412746', 'sentence': '1'}, []),\n",
       "  Annotation(chunk, 140, 155, machine learning, {'score': '0.4669110728865977', 'sentence': '1'}, []),\n",
       "  Annotation(chunk, 148, 168, learning competitions, {'score': '0.7629341092553145', 'sentence': '1'}, []),\n",
       "  Annotation(chunk, 262, 271, cloud next, {'score': '0.5148655855734479', 'sentence': '2'}, []),\n",
       "  Annotation(chunk, 268, 282, next conference, {'score': '0.9946053144191087', 'sentence': '2'}, []),\n",
       "  Annotation(chunk, 411, 427, anthony goldbloom, {'score': '1.3234188962127715', 'sentence': '3'}, []),\n",
       "  Annotation(chunk, 419, 436, goldbloom declined, {'score': '1.0783767054763957', 'sentence': '3'}, []),\n",
       "  Annotation(chunk, 559, 570, million data, {'score': '1.2105649553726812', 'sentence': '4'}, []),\n",
       "  Annotation(chunk, 567, 581, data scientists, {'score': '0.5625814127416624', 'sentence': '4'}, []),\n",
       "  Annotation(chunk, 629, 638, ben hamner, {'score': '0.6232788821367888', 'sentence': '4'}, []),\n",
       "  Annotation(chunk, 887, 898, running data, {'score': '1.1837552148990067', 'sentence': '6'}, []),\n",
       "  Annotation(chunk, 895, 906, data science, {'score': '0.2558562206412746', 'sentence': '6'}, []),\n",
       "  Annotation(chunk, 912, 927, machine learning, {'score': '0.4669110728865977', 'sentence': '6'}, []),\n",
       "  Annotation(chunk, 920, 940, learning competitions, {'score': '0.7629341092553145', 'sentence': '6'}, []),\n",
       "  Annotation(chunk, 1024, 1038, data scientists, {'score': '0.5625814127416624', 'sentence': '7'}, []),\n",
       "  Annotation(chunk, 1333, 1348, machine learning, {'score': '0.4669110728865977', 'sentence': '9'}, []),\n",
       "  Annotation(chunk, 1450, 1461, google cloud, {'score': '0.6119601374956966', 'sentence': '10'}, []),\n",
       "  Annotation(chunk, 1457, 1470, cloud platform, {'score': '0.7963378537048375', 'sentence': '10'}, []),\n",
       "  Annotation(chunk, 2197, 2210, index ventures, {'score': '0.9046380566931278', 'sentence': '17'}, []),\n",
       "  Annotation(chunk, 2213, 2220, sv angel, {'score': '1.0455865632562458', 'sentence': '17'}, []),\n",
       "  Annotation(chunk, 2223, 2233, max levchin, {'score': '1.0455865632562458', 'sentence': '17'}, []),\n",
       "  Annotation(chunk, 2236, 2249, naval ravikant, {'score': '1.0455865632562458', 'sentence': '17'}, []),\n",
       "  Annotation(chunk, 2275, 2284, hal varian, {'score': '1.0455865632562458', 'sentence': '17'}, []),\n",
       "  Annotation(chunk, 2287, 2301, khosla ventures, {'score': '0.9046380566931278', 'sentence': '17'}, []),\n",
       "  Annotation(chunk, 2307, 2317, yuri milner, {'score': '1.0089569601318893', 'sentence': '17'}, []),\n",
       "  Annotation(chunk, 1, 19, google is acquiring, {'score': '1.03925351066703', 'sentence': '0'}, []),\n",
       "  Annotation(chunk, 11, 32, acquiring data science, {'score': '1.2638604889983422', 'sentence': '0'}, []),\n",
       "  Annotation(chunk, 73, 91, google is acquiring, {'score': '1.03925351066703', 'sentence': '1'}, []),\n",
       "  Annotation(chunk, 128, 146, science and machine, {'score': '1.257899565028052', 'sentence': '1'}, []),\n",
       "  Annotation(chunk, 262, 282, cloud next conference, {'score': '1.2426105944332113', 'sentence': '2'}, []),\n",
       "  Annotation(chunk, 900, 918, science and machine, {'score': '1.257899565028052', 'sentence': '6'}, []),\n",
       "  Annotation(chunk, 1450, 1470, google cloud platform, {'score': '1.0706148536930595', 'sentence': '10'}, [])]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682ef7fd-3cdc-4876-a08b-41fa4d4c925a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
